---
title: "16 â€” Tests et debugging"
tags: ["Web Audio API", "tests", "debug", "unit", "integration", "end-to-end", "Jest", "stubs", "mocks", "OfflineAudioContext", "automation", "profiling"]
icon: "ðŸ“˜"
created: "2025-12-21"
---

# ðŸ“˜ 16 â€” Tests et debugging

> ðŸŽ¯ **Objectif du chapitre** : Mettre en place une **stratÃ©gie de tests** et des **outils de debug** pour des applications Web Audio fiables : **tests unitaires** (logiques pures : conversions, scheduling), **tests dâ€™intÃ©gration** (stubs/mocks dâ€™`AudioParam`/nÅ“uds), **tests endâ€‘toâ€‘end** (geste utilisateur, transport), vÃ©rification par **OfflineAudioContext**, et **traces** utiles (automation, connexions, clipping).

---

## ðŸ§  Pourquoi tester ? (dÃ©finition, pourquoi, analogie)

- **DÃ©finition** : Tester Web Audio consiste Ã  **valider la logique musicale** (tempo, planning), **lâ€™orchestration du graphe**, et les **contrats dâ€™API** (Automation, start/stop) sans nÃ©cessairement produire du son rÃ©el en CI.
- **Pourquoi** : Ã©viter les **ratÃ©s** de scheduling, les **fuites** de nÅ“uds, les **clippings** en sortie; garantir une **UX prÃ©visible**.
- **Analogie** : Comme un **chef dâ€™orchestre** qui vÃ©rifie la **partition** et le **placement** des instruments avant le concert.

---

## ðŸ§  PÃ©rimÃ¨tre des tests

- **Unitaires (logique pure)** : conversions **BPM â†” secondes**, **notes â†” Hz**, **ADSR** calculÃ©, **fenÃªtre de lookahead**.
- **IntÃ©gration (API simulÃ©e)** : stubs dâ€™`AudioParam` et de nÅ“uds (gain, filtre) pour **enregistrer** les automations/connexions.
- **Endâ€‘toâ€‘end** : geste utilisateur â†’ `resume()` â†’ dÃ©marrage du transport; vÃ©rification dâ€™Ã©tats UI.
- **Validation de rendu** : **OfflineAudioContext** pour produire un `AudioBuffer` et **mesurer** RMS/peak/durÃ©e.

---

## ðŸ§  Unitaires (logique pure)

### ðŸ”¢ Conversions et tempo (JS)
```js
export function secondsPerBeat(bpm){ return 60 / bpm; }
export function secondsPerStep(bpm, stepsPerBeat = 4){ return (60 / bpm) / stepsPerBeat; }
export function midiToHz(m){ return 440 * Math.pow(2, (m - 69) / 12); }
```

### ðŸ”§ Test minimal (sans framework)
```js
function assertApprox(name, actual, expected, eps = 1e-6){
  if (Math.abs(actual - expected) > eps) throw new Error(`${name}: ${actual} != ${expected}`);
}

// Exemples:
assertApprox('spb@120', secondsPerBeat(120), 0.5);
assertApprox('hz@A4', midiToHz(69), 440);
```

### ðŸ”¢ FenÃªtre de lookahead
```js
export function nextTimes(currentTime, sp, horizon){
  const out = [];
  let t = currentTime;
  while (t < currentTime + horizon){ t += sp; out.push(t); }
  return out;
}
```

---

## ðŸ§  IntÃ©gration : stubs/mocks pour `AudioParam` et nÅ“uds

> ðŸ’¡ **IdÃ©e** : Simuler lâ€™API pour **capturer** automations & connexions et **affirmer** leurs propriÃ©tÃ©s (ordre, valeurs, temps).

### ðŸ”§ `StubAudioParam` (capture des automations)
```js
export class StubAudioParam {
  constructor(){ this.events = []; this.value = 0; }
  setValueAtTime(v, t){ this.events.push({ type:'set', v, t }); this.value = v; }
  linearRampToValueAtTime(v, t){ this.events.push({ type:'lin', v, t }); this.value = v; }
  exponentialRampToValueAtTime(v, t){ this.events.push({ type:'exp', v, t }); this.value = v; }
  setTargetAtTime(v, t, tau){ this.events.push({ type:'target', v, t, tau }); this.value = v; }
  cancelScheduledValues(t){ this.events.push({ type:'cancel', t }); }
}
```

### ðŸ”§ `StubGainNode` & `StubNode`
```js
export class StubNode {
  constructor(name){ this.name = name; this.outputs = new Set(); }
  connect(node){ this.outputs.add(node); return node; }
  disconnect(){ this.outputs.clear(); }
}

export class StubGainNode extends StubNode {
  constructor(name = 'Gain'){ super(name); this.gain = new StubAudioParam(); }
}
```

### ðŸ”§ Assertion utilitaire
```js
export function assertEventsSequential(param, types){
  const seq = param.events.map(e => e.type).join(',');
  const expected = types.join(',');
  if (seq !== expected) throw new Error(`events: ${seq} != ${expected}`);
}
```

### ðŸ§ª Exemple : programmer une ADSR sur un stub
```js
import { StubGainNode, assertEventsSequential } from './stubs.js';

function scheduleADSR(currentTime, gainParam, {A=0.01,D=0.2,S=0.5}={}){
  const now = currentTime;
  gainParam.cancelScheduledValues(now);
  gainParam.setValueAtTime(0, now);
  gainParam.linearRampToValueAtTime(1, now + A);
  gainParam.linearRampToValueAtTime(S, now + A + D);
}

const gain = new StubGainNode();
scheduleADSR(10.0, gain.gain, {A:0.02, D:0.2, S:0.5});
assertEventsSequential(gain.gain, ['cancel','set','lin','lin']);
```

---

## ðŸ§  Endâ€‘toâ€‘end minimal : geste utilisateur & transport

### ðŸ”§ Bouton dâ€™activation + transport (test manuel)
```html
<button id="enable">Activer</button>
<button id="play">Play</button>
<button id="pause">Pause</button>
<script>
const ctx = new AudioContext();
let running = false;

enable.onclick = async () => { await ctx.resume(); running = true; };
play.onclick = async () => { if (ctx.state !== 'running') await ctx.resume(); /* dÃ©marrer sources */ };
pause.onclick = async () => { await ctx.suspend(); /* arrÃªter timers */ };
</script>
```

> âš ï¸ **Conseil** : vÃ©rifie que **aucun son** ne dÃ©marre **sans** activation; que la reprise **recalcule** bien les planifications (chap. 6).

---

## ðŸ§  Validation par OfflineAudioContext

> ðŸ’¡ **But** : rendre hors temps rÃ©el et **mesurer**.

### ðŸ”§ Rendu + mesures
```js
async function measureOffline(seconds = 1.0){
  const sr = 44100; const len = Math.floor(sr * seconds);
  const ctx = new OfflineAudioContext(1, len, sr);
  const osc = ctx.createOscillator(); osc.frequency.value = 440;
  const amp = ctx.createGain(); amp.gain.value = 0.5;
  osc.connect(amp).connect(ctx.destination);
  osc.start(0); osc.stop(seconds);
  const buf = await ctx.startRendering();
  let acc=0, peak=0; const x = buf.getChannelData(0);
  for(let i=0;i<x.length;i++){ acc += x[i]*x[i]; peak = Math.max(peak, Math.abs(x[i])); }
  const rms = Math.sqrt(acc/x.length);
  return { duration: buf.duration, peak, rms };
}
```

### ðŸ”§ Assertion
```js
measureOffline(1.0).then(m => {
  if (Math.abs(m.duration - 1.0) > 1e-3) throw new Error('duration mismatch');
  if (m.peak <= 0) throw new Error('silent render');
});
```

---

## ðŸ§  Traces & outils de debug maison

### ðŸ”§ Tracer les connexions (graph)
```js
export function attachTraceConnect(){
  const orig = AudioNode.prototype.connect;
  AudioNode.prototype.connect = function(target){
    console.log(`[connect] ${this.constructor.name} -> ${target.constructor.name}`);
    return orig.call(this, target);
  };
}
```

### ðŸ”§ Tracer les automations
```js
export function traceParam(param, label){
  const wrap = (fn, type) => function(...args){
    console.log(`[param:${label}] ${type}`, ...args);
    return fn.apply(this, args);
  };
  param.setValueAtTime = wrap(param.setValueAtTime, 'set');
  param.linearRampToValueAtTime = wrap(param.linearRampToValueAtTime, 'lin');
  param.exponentialRampToValueAtTime = wrap(param.exponentialRampToValueAtTime, 'exp');
  param.setTargetAtTime = wrap(param.setTargetAtTime, 'target');
}
```

### ðŸ”§ DÃ©tecter clipping (AnalyserNode)
```js
export function watchClipping(analyser){
  const buf = new Float32Array(analyser.fftSize);
  function loop(){
    analyser.getFloatTimeDomainData(buf);
    let clip = false;
    for(let i=0;i<buf.length;i++){ if (buf[i] >= 0.999 || buf[i] <= -0.999) { clip = true; break; } }
    if (clip) console.warn('CLIPPING detected');
    requestAnimationFrame(loop);
  }
  requestAnimationFrame(loop);
}
```

---

## ðŸ§  Patterns de conception pour testabilitÃ©

- **Service Audio** (faÃ§ade) : encapsule `AudioContext`, expose des mÃ©thodes (**playNote**, **connectEffect**). Permet dâ€™**injecter** des stubs en tests.
- **SÃ©paration** **logiciel/audio** : fonctions de tempo/planning **pures** sans dÃ©pendances.
- **Adaptateurs** : objets qui traduisent une **API** (param) en **Ã©vÃ©nements testables**.

### ðŸ”§ Exemple de faÃ§ade simplifiÃ©e
```js
export class AudioEngine {
  constructor(ctx = new AudioContext()){
    this.ctx = ctx;
    this.master = ctx.createGain(); this.master.gain.value = 0.8;
    this.master.connect(ctx.destination);
  }
  async ensureRunning(){ if (this.ctx.state !== 'running') await this.ctx.resume(); }
  playBeep(freq = 440, length = 0.1){
    const osc = this.ctx.createOscillator(); const g = this.ctx.createGain();
    osc.frequency.value = freq; g.gain.value = 0;
    osc.connect(g).connect(this.master);
    const t = this.ctx.currentTime; g.gain.setValueAtTime(0, t); g.gain.linearRampToValueAtTime(0.8, t+0.005);
    g.gain.linearRampToValueAtTime(0, t+length);
    osc.start(t); osc.stop(t+length+0.01);
    return { osc, g };
  }
}
```

---

## ðŸ§© SchÃ©mas Mermaid

### Pyramide des tests
```mermaid
graph LR
  Unit[Unit (logique pure)] --> Int[Integration (stubs)]
  Int --> E2E[End-to-end (UI + gesture)]
  E2E --> Offline[Offline render (validation)]
```

### Traces & contrÃ´les
```mermaid
graph LR
  Param[AudioParam] --> Trace[traceParam]
  Node[AudioNode] --> TraceConn[attachTraceConnect]
  Out[Master] --> ClipWatch[watchClipping]
```

---

## ðŸ”§ Exercices (progressifs)

1. **Unit** : Ã©cris des tests sur `secondsPerBeat`, `midiToHz`, `nextTimes`.
2. **Integration** : utilise `StubAudioParam` pour valider une enveloppe ADSR (ordre et timings).
3. **Offline** : rends 2 s dâ€™un motif avec `OfflineAudioContext`; mesure **duration**, **peak**, **rms**.
4. **Trace** : active `attachTraceConnect()` et vÃ©rifie le routage durant la construction du pÃ©dalboard (chap. 10).
5. **Clipping** : place `watchClipping()` sur le master; dÃ©clenche volontairement un clipping et observe lâ€™alerte.
6. **FaÃ§ade** : teste `AudioEngine.playBeep()` en **simulation** (stubs) pour vÃ©rifier automations.

---

## ðŸ’¡ Astuces & bonnes pratiques

- **Tester tÃ´t** : la logique de tempo/planning peut Ãªtre validÃ©e **sans** audio rÃ©el.
- **Ã‰viter** dâ€™asserter des **valeurs audio** exactes (sensibles aux implÃ©mentations); prÃ©fÃ¨re des **invariants** (ordre, temps, bornes).
- **Tracer** en dev, **dÃ©sactiver** en prod (logs coÃ»teux).
- **Offline** pour les **vÃ©rifications de rendu** et les **exports**.

---

## âš ï¸ PiÃ¨ges frÃ©quents

- **Rejouer** un `AudioBufferSourceNode` : impossible â†’ recrÃ©er.
- **Automations** exponentielles vers `0` : interdit â†’ utiliser **epsilon**.
- **Planifier** avec `setTimeout` : jitter â†’ prÃ©fÃ©rer **horloge audio**.
- **Oublier** `disconnect()` en fin de test : fuites et Ã©tats polluÃ©s.

---

## ðŸ§¾ RÃ©sumÃ© du chapitre (points clÃ©s)

- **Quatre axes** : unitaires, intÃ©gration, endâ€‘toâ€‘end, offline.
- **Stubs** capturent automations & connexions; valider **ordre/temps**.
- **OfflineAudioContext** produit des buffers mesurables (RMS/peak/durÃ©e).
- **Traces** (connexions, params) + **dÃ©tection clipping** pour le debug.
- **Bonnes pratiques** : invariants plutÃ´t que samples exacts; nettoyer les nÅ“uds.

---

> âœ… **Prochaines Ã©tapes** : **Chapitre 17 â€” IntÃ©gration : TypeScript, bundlers et frameworks** (service audio typÃ©, Vite/Webpack, Vue/React).
