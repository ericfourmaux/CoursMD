---
title: "11 â€” Microphone et traitement en temps rÃ©el"
tags: ["Web Audio API", "getUserMedia", "MediaStreamAudioSourceNode", "micro", "latence", "echoCancellation", "noiseSuppression", "autoGainControl", "permissions", "sÃ©curitÃ©", "VU", "gate", "devices"]
icon: "ğŸ“˜"
created: "2025-12-21"
---

# ğŸ“˜ 11 â€” Microphone et traitement en temps rÃ©el

> ğŸ¯ **Objectif du chapitre** : Obtenir lâ€™entrÃ©e **micro** du navigateur via `getUserMedia`, crÃ©er un `MediaStreamAudioSourceNode`, traiter le son **en direct** (VUâ€‘mÃ¨tre, gate simple, EQ), gÃ©rer **latence/Ã©cho** et **permissions**, choisir la **source dâ€™entrÃ©e** et nettoyer correctement les **tracks**.

---

## ğŸ§  PrÃ©requis & sÃ©curitÃ©

- **HTTPS requis** pour accÃ©der aux pÃ©riphÃ©riques (micro/camÃ©ra).
- **Permission utilisateur** : le navigateur affiche un **prompt**. Respecter le geste utilisateur et **expliquer** lâ€™usage.
- **Autoplay & micro** : lâ€™acquisition micro nâ€™est pas soumise Ã  lâ€™autoplay, mais la **lecture** (loopback) lâ€™est; utiliser `ctx.resume()` sur geste.

---

## ğŸ§  Obtenir le flux micro : `getUserMedia`

### ğŸ›ï¸ Contraintes utiles
- `echoCancellation: true` â€” rÃ©duit le **larsen**/Ã©cho (pour le chat).
- `noiseSuppression: true` â€” attÃ©nue le **bruit** ambiant.
- `autoGainControl: false` â€” Ã©viter les variations de niveau automatiques.
- `latency` (hint) â€” cible de latence si disponible.

```js
async function getMicStream(constraints = {
  audio: {
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: false,
    channelCount: 1,        // mono conseillÃ©
    sampleRate: 44100,      // hint, pas garanti
    latency: 0              // hint (faible latence)
  }
}){
  try {
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    return stream;
  } catch (err) {
    console.error('getUserMedia error:', err.name, err.message);
    throw err;
  }
}
```

---

## ğŸ§  CrÃ©er la source audio du graph : `MediaStreamAudioSourceNode`

```js
const ctx = new AudioContext();
const stream = await getMicStream();
const mic = ctx.createMediaStreamSource(stream);

// Exemple de chaÃ®ne: mic -> analyser -> destination (loopback)
const analyser = ctx.createAnalyser(); analyser.fftSize = 1024;
const master = ctx.createGain(); master.gain.value = 0.0; // par dÃ©faut, pas de loopback

mic.connect(analyser);
analyser.connect(master).connect(ctx.destination);

// Sur geste utilisateur: await ctx.resume();
```

> âš ï¸ **Loopback** (Ã©couter sa propre voix) peut crÃ©er un **larsen** sans casque. Utiliser `echoCancellation: true` et **baisser** `master.gain`.

---

## ğŸ§ª VUâ€‘mÃ¨tre en temps rÃ©el (RMS + peak)

```js
function attachVUMeter(analyser, canvas){
  const ctx2d = canvas.getContext('2d');
  const w = canvas.width, h = canvas.height;
  const buf = new Float32Array(analyser.fftSize);
  let ema = 0; const alpha = 0.85; // lissage EMA

  function draw(){
    analyser.getFloatTimeDomainData(buf);
    // RMS
    let acc = 0, peak = 0;
    for(let i=0;i<buf.length;i++){ acc += buf[i]*buf[i]; peak = Math.max(peak, Math.abs(buf[i])); }
    const rms = Math.sqrt(acc / buf.length);
    // EMA pour stabilitÃ© visuelle
    ema = (1-alpha) * rms + alpha * ema;

    ctx2d.clearRect(0,0,w,h);
    // Barre RMS
    ctx2d.fillStyle = '#1f77b4';
    ctx2d.fillRect(10, h-20, (w-20) * Math.min(ema, 1), 10);
    // Pic
    ctx2d.fillStyle = '#d62728';
    ctx2d.fillRect(10 + (w-20) * Math.min(peak, 1), h-35, 2, 25);

    requestAnimationFrame(draw);
  }
  requestAnimationFrame(draw);
}
```

---

## ğŸ§  Gate simple (ouverture/fermeture sur seuil)

> ğŸ’¡ **IdÃ©e** : si `RMS` < **seuil**, on coupe la sortie (via `GainNode`). On lisse lâ€™ouverture/fermeture avec `setTargetAtTime`.

```js
function attachGate(analyser, outGain, {threshold=0.02, openTau=0.03, closeTau=0.15}={}){
  const buf = new Float32Array(analyser.fftSize);
  let isOpen = false;

  function tick(){
    analyser.getFloatTimeDomainData(buf);
    let acc = 0; for(let i=0;i<buf.length;i++) acc += buf[i]*buf[i];
    const rms = Math.sqrt(acc / buf.length);
    const now = outGain.context.currentTime;
    if (!isOpen && rms >= threshold){
      isOpen = true;
      outGain.gain.setTargetAtTime(1, now, openTau);
    } else if (isOpen && rms < threshold){
      isOpen = false;
      outGain.gain.setTargetAtTime(0, now, closeTau);
    }
    requestAnimationFrame(tick);
  }
  requestAnimationFrame(tick);
}

// Utilisation
const gateOut = ctx.createGain(); gateOut.gain.value = 0;
mic.connect(analyser);
analyser.connect(gateOut).connect(ctx.destination);
attachGate(analyser, gateOut, { threshold: 0.025 });
```

> âš ï¸ **Note** : Ce gate est **basique** et sensible au **bruit**; pour meilleure performance, prÃ©fÃ©rer **AudioWorklet** pour un traitement audioâ€‘rate.

---

## ğŸ§  Choisir lâ€™entrÃ©e (device) & permissions

```js
// Lister devices (aprÃ¨s une premiÃ¨re permission accordÃ©e)
const devices = await navigator.mediaDevices.enumerateDevices();
const inputs = devices.filter(d => d.kind === 'audioinput');
console.table(inputs.map(d => ({label: d.label, deviceId: d.deviceId})));

// SÃ©lectionner un device spÃ©cifique
async function getMicByDeviceId(deviceId){
  return await navigator.mediaDevices.getUserMedia({ audio: { deviceId, echoCancellation: true } });
}
```

> ğŸ’¡ **Astuce** : Les **labels** des devices ne sont accessibles **quâ€™aprÃ¨s** autorisation.

---

## ğŸ§  Latence, sample rate & stabilitÃ©

- **Latence** : dÃ©pend du **matÃ©riel** et du navigateur; viser un **buffer court** (Web Audio est interne).
- **Sample rate** : `ctx.sampleRate` (souvent 44.1 kHz/48 kHz). Le flux micro peut Ãªtre **resamplÃ©**.
- **Suspension** : `ctx.suspend()` met lâ€™audio en pause (lâ€™horloge nâ€™avance plus). Reprendre avec `ctx.resume()`.
- **Nettoyage** : `stream.getTracks().forEach(t => t.stop())` pour **libÃ©rer** le micro; `node.disconnect()` pour le graphe.

```js
function stopMic(stream){ stream.getTracks().forEach(t => t.stop()); }
```

---

## ğŸ§© SchÃ©mas Mermaid

### Micro â†’ Gate â†’ Destination (avec VU)
```mermaid
graph LR
  Mic[MediaStreamAudioSource] --> An[Analyser]
  An --> Gate[Gain (gate)]
  Gate --> Out[Destination]
```

### SÃ©lection dâ€™entrÃ©e & Loopback contrÃ´lÃ©
```mermaid
graph LR
  Devices[enumerateDevices] --> Select[deviceId]
  Select --> getUserMedia
  getUserMedia --> MicSrc
  MicSrc --> FX[EQ/Comp]
  FX --> Master[Gain]
  Master --> Out[Destination]
```

---

## ğŸ”§ Exercices (progressifs)

1. **VUâ€‘mÃ¨tre** : ajoute un slider de **lissage** (alpha) et observe la rÃ©activitÃ©.
2. **Gate** : ajuste `threshold/openTau/closeTau` pour un environnement **bruyant**/**silencieux**.
3. **EQ live** : place un `BiquadFilter` (chap. 5) aprÃ¨s le micro et balaye la frÃ©quence.
4. **Comp live** : ajoute un `DynamicsCompressorNode` pour contrÃ´ler les **pics**.
5. **SÃ©lection device** : liste les `audioinput` et propose un menu **select** pour choisir la source.
6. **Nettoyage** : implÃ©mente un bouton **Stop** qui appelle `stopMic(stream)` et `disconnect()`.

---

## ğŸ’¡ Astuces & bonnes pratiques

- **Casque** recommandÃ© pour Ã©viter **larsen** en loopback.
- **RÃ©glages** : commencer avec `echoCancellation`/`noiseSuppression` **activÃ©s** pour la voix.
- **UI** : afficher lâ€™Ã©tat **permission accordÃ©e/refusÃ©e** et **device sÃ©lectionnÃ©**.
- **Performance** : limiter les **visualisations** coÃ»teuses; utiliser `requestAnimationFrame`.

---

## âš ï¸ PiÃ¨ges frÃ©quents

- **Oublier** `HTTPS` â†’ `getUserMedia` Ã©choue.
- **Labels vides** : sans permission, `enumerateDevices()` ne donne pas de labels.
- **Loopback trop fort** : feedback; baisser `master.gain` ou activer `echoCancellation`.
- **Ne pas stopper** les tracks â†’ micro reste allumÃ©.

---

## ğŸ§¾ RÃ©sumÃ© du chapitre (points clÃ©s)

- **Micro** via `getUserMedia` (contraintes de rÃ©duction de bruit/Ã©cho).
- **Source** `MediaStreamAudioSourceNode` dans le **graph** Web Audio.
- **VUâ€‘mÃ¨tre** en **temps rÃ©el** (RMS + peak) et **gate** basique.
- **Devices** : `enumerateDevices` â†’ choisir `deviceId`.
- **Latence & nettoyage** : surveiller `ctx.state`, stopper les **tracks** proprement.

---

> âœ… **Prochaines Ã©tapes** : **Chapitre 12 â€” AudioWorklet (processing custom) & WASM (intro)** : crÃ©er un processeur sur le thread audio et prÃ©parer des DSP plus avancÃ©s.
