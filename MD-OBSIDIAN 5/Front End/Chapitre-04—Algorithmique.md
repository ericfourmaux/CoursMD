
# ğŸ“˜ Chapitre 4 â€” Algorithmique & Structures de DonnÃ©es en JavaScript

> ğŸ¯ **Objectifs du chapitre**
> - Comprendre et **mesurer** la complexitÃ© temporelle et spatiale (**Bigâ€‘O**), avec des exemples et formules en **JavaScript**.
> - MaÃ®triser les **structures de donnÃ©es** essentielles: Array, Object/Map, Set, Pile (Stack), File (Queue), Liste chaÃ®nÃ©e, Deque, **Heap (file de prioritÃ©)**.
> - ImplÃ©menter les **algorithmes** classiques: recherche linÃ©aire/binaire, tris (insertion, sÃ©lection, merge sort, quicksort), **parcours** (DFS/BFS), **rÃ©cursion** et **programmation dynamique**.
> - Appliquer des **patterns** (deux pointeurs, fenÃªtre glissante, hashage) pour rÃ©soudre efficacement des problÃ¨mes courants.
> - Produire une **bibliothÃ¨que dâ€™algos** testable en JS et savoir **benchmark** correctement.

---

## ğŸ§  1. Notation Bigâ€‘O â€” Comprendre la croissance

### ğŸ” DÃ©finition
La **notation Bigâ€‘O** dÃ©crit la **limite supÃ©rieure** de la croissance du **nombre dâ€™opÃ©rations** (ou de la mÃ©moire) en fonction de la taille dâ€™entrÃ©e `n`. Elle **abstrait** les constantes et les termes de plus faible ordre.

### â“ Pourquoi
- Comparer des **solutions** indÃ©pendamment du matÃ©riel.
- PrÃ©voir lâ€™**Ã©chelle** (scalabilitÃ©) quand `n` devient grand.

### ğŸ’¡ Analogies
- **Autoroute**: la capacitÃ© (Bigâ€‘O) indique comment le temps de trajet croÃ®t avec le nombre de vÃ©hicules `n`. Les feux, limitations (constantes) varient, mais lâ€™**ordre de grandeur** prime.
- **Cuisine**: cuisiner `n` plats avec un plan linÃ©aire (`O(n)`), ou en divisions/combinaisons (`O(n log n)`), etc.

### ğŸ§® Formules en JavaScript (croissances usuelles)
```js
const O = {
  constant: (n) => 1,
  linear: (n) => n,
  quadratic: (n) => n * n,
  cubic: (n) => n ** 3,
  log: (n) => Math.log2(Math.max(1, n)),
  nlogn: (n) => n * Math.log2(Math.max(1, n)),
};
// Exemple: comparer les ordres de grandeur
for (const n of [10, 100, 1000]) {
  console.log(n, {
    O1: O.constant(n), On: O.linear(n), Onlogn: Math.round(O.nlogn(n)), On2: O.quadratic(n)
  });
}
```

### âœ… Tableau (ordre croissant)
- `O(1)` < `O(log n)` < `O(n)` < `O(n log n)` < `O(n^2)` < `O(n^3)` < `O(2^n)` < `O(n!)`

### âš ï¸ SubtilitÃ©s
- **Constantes** comptent pour des `n` **petits**.
- **Cache** CPU, **allocation mÃ©moire** et **JIT** peuvent varier; Bigâ€‘O reste **thÃ©orique**.

---

## ğŸ§  2. Mesurer le temps en JavaScript â€” Benchmarking

### ğŸ” Principe
Utiliser `performance.now()` pour mesurer des **intervalles**; rÃ©pÃ©ter plusieurs fois, Ã©liminer lâ€™outlier et **Ã©viter la suppression de code** par le JIT.

### ğŸ’¡ Harness de benchmark
```js
function bench(label, fn, { warmup = 100, runs = 200 } = {}) {
  // Warmup pour JIT
  for (let i = 0; i < warmup; i++) fn();
  const times = [];
  for (let i = 0; i < runs; i++) {
    const t0 = performance.now();
    const res = fn(); // Ã©viter dead code: utiliser res
    const t1 = performance.now();
    times.push(t1 - t0);
    if (typeof res === 'number') { // empÃªcher optimisation excessive
      // Petite opÃ©ration sur res
      Math.sqrt(res);
    }
  }
  times.sort((a,b)=>a-b);
  const mid = times[Math.floor(times.length/2)];
  console.log(`${label}: mÃ©diane = ${mid.toFixed(3)} ms (runs=${runs})`);
  return mid;
}
```

### âš ï¸ Bonnes pratiques
- Mesurer sur **profil rÃ©aliste** (taille de `n`, structure de donnÃ©es).
- **DÃ©sactiver** extensions/breakpoints; exÃ©cuter plusieurs **sÃ©ries**.

---

## ğŸ§  3. Structures de donnÃ©es fondamentales

### ğŸ“¦ Array (tableau)
- **Indexation** O(1), `push/pop` O(1) amorti, `shift/unshift` O(n).
- **Parcours** O(n), **recherche** naÃ¯ve O(n).
```js
const arr = [3,1,4];
arr.push(1);   // O(1)
arr.shift();   // O(n)
arr.includes(4); // O(n)
```

### ğŸ“¦ Object vs Map & Set
- **Object**: clÃ©s **string/symbol**, prototype, risque de collisions.
- **Map**: clÃ©s **de tout type**, **ordre dâ€™insertion**, itÃ©rations optimisÃ©es.
- **Set**: collection dâ€™Ã©lÃ©ments **uniques**.
```js
// Comptage de frÃ©quences (hash)
function freq(xs) {
  const m = new Map();
  for (const x of xs) m.set(x, (m.get(x) || 0) + 1);
  return m;
}
```

### ğŸ“¦ Pile (Stack)
- LIFO (Last In, First Out): `push`, `pop` O(1).
```js
class Stack {
  constructor(){ this.s = []; }
  push(x){ this.s.push(x); }
  pop(){ return this.s.pop(); }
  peek(){ return this.s[this.s.length-1]; }
}
```

### ğŸ“¦ File (Queue) â€” Deux piles (amorti O(1))
```js
class Queue {
  constructor(){ this.in=[]; this.out=[]; }
  enqueue(x){ this.in.push(x); }
  dequeue(){ if(!this.out.length){ while(this.in.length) this.out.push(this.in.pop()); }
             return this.out.pop(); }
  get size(){ return this.in.length + this.out.length; }
}
```

### ğŸ“¦ Liste chaÃ®nÃ©e (Singly Linked List)
```js
class Node { constructor(val, next=null){ this.val=val; this.next=next; } }
class LinkedList {
  constructor(){ this.head=null; }
  prepend(val){ this.head = new Node(val, this.head); }
  find(val){ let cur=this.head; while(cur){ if(cur.val===val) return cur; cur=cur.next; } return null; }
}
```
- **Insertion** en tÃªte O(1), **recherche** O(n).

### ğŸ“¦ Deque (doubleâ€‘ended queue)
```js
class Deque {
  constructor(){ this.left=[]; this.right=[]; }
  pushLeft(x){ this.left.push(x); }
  pushRight(x){ this.right.push(x); }
  popLeft(){ if(!this.left.length) while(this.right.length) this.left.push(this.right.shift()); return this.left.pop(); }
  popRight(){ if(!this.right.length) while(this.left.length) this.right.unshift(this.left.pop()); return this.right.pop(); }
}
```

### ğŸ“¦ Heap (File de prioritÃ©) â€” **Binary heap**
```js
class MinHeap {
  constructor(){ this.h=[]; }
  push(x){ this.h.push(x); this.#up(this.h.length-1); }
  pop(){ if(!this.h.length) return undefined; const top=this.h[0];
         const x=this.h.pop(); if(this.h.length){ this.h[0]=x; this.#down(0); } return top; }
  #up(i){ while(i){ const p=(i-1)>>1; if(this.h[p] <= this.h[i]) break; [this.h[p],this.h[i]]=[this.h[i],this.h[p]]; i=p; } }
  #down(i){ for(;;){ const l=i*2+1, r=l+1; let m=i;
    if(l<this.h.length && this.h[l] < this.h[m]) m=l;
    if(r<this.h.length && this.h[r] < this.h[m]) m=r;
    if(m===i) break; [this.h[i],this.h[m]]=[this.h[m],this.h[i]]; i=m; }
  }
}
```
- `push`/`pop` **O(log n)**.

---

## ğŸ§  4. Recherche â€” linÃ©aire & binaire

### ğŸ” Recherche linÃ©aire
- Parcours sÃ©quentiel **O(n)**.
```js
function linearSearch(xs, target){
  for (let i=0;i<xs.length;i++) if (xs[i]===target) return i;
  return -1;
}
```

### ğŸ” Recherche binaire (tableau **triÃ©**)
- Diviser pour chercher **O(log n)**.
```js
function binarySearch(xs, target){
  let lo=0, hi=xs.length-1;
  while (lo<=hi){
    const mid=(lo+hi)>>1;
    if (xs[mid]===target) return mid;
    if (xs[mid]<target) lo=mid+1; else hi=mid-1;
  }
  return -1;
}
```

---

## ğŸ§  5. Tris â€” propriÃ©tÃ©s & implÃ©mentations

### ğŸ” StabilitÃ©
Un tri **stable** conserve lâ€™ordre relatif des Ã©lÃ©ments Ã©gaux (utile pour **multiâ€‘clÃ©s**).

### ğŸ“¦ Insertion sort (stable) â€” **O(n^2)**
```js
function insertionSort(a){
  for(let i=1;i<a.length;i++){
    const x=a[i]; let j=i-1;
    while(j>=0 && a[j]>x){ a[j+1]=a[j]; j--; }
    a[j+1]=x;
  }
  return a;
}
```

### ğŸ“¦ Selection sort (instable) â€” **O(n^2)**
```js
function selectionSort(a){
  for(let i=0;i<a.length;i++){
    let m=i;
    for(let j=i+1;j<a.length;j++) if(a[j]<a[m]) m=j;
    [a[i],a[m]]=[a[m],a[i]];
  }
  return a;
}
```

### ğŸ“¦ Merge sort (stable) â€” **O(n log n)**, **O(n)** espace
```js
function mergeSort(a){
  if(a.length<=1) return a.slice();
  const mid=a.length>>1;
  const left=mergeSort(a.slice(0,mid));
  const right=mergeSort(a.slice(mid));
  const res=[]; let i=0,j=0;
  while(i<left.length && j<right.length){
    if(left[i]<=right[j]) res.push(left[i++]); else res.push(right[j++]);
  }
  return res.concat(left.slice(i), right.slice(j));
}
```

### ğŸ“¦ Quicksort (pivot) â€” **O(n log n)** moyen, **O(n^2)** pire
```js
function quickSort(a, lo=0, hi=a.length-1){
  if(lo>=hi) return a;
  const p = partition(a, lo, hi);
  quickSort(a, lo, p-1);
  quickSort(a, p+1, hi);
  return a;
}
function partition(a, lo, hi){
  const pivot=a[hi]; let i=lo;
  for(let j=lo;j<hi;j++) if(a[j]<pivot){ [a[i],a[j]]=[a[j],a[i]]; i++; }
  [a[i],a[hi]]=[a[hi],a[i]]; return i;
}
```

### ğŸ§® Estimations en JS
```js
// Comparer n log n vs n^2
function steps_nlogn(n){ return Math.round(n * Math.log2(Math.max(1,n))); }
function steps_n2(n){ return n*n; }
console.log(1000, { nlogn: steps_nlogn(1000), n2: steps_n2(1000) });
```

---

## ğŸ§  6. RÃ©cursion & Programmation Dynamique (PD)

### ğŸ” RÃ©cursion
- **Cas de base** + **cas rÃ©cursif**. Risque de **stack overflow** si la profondeur est grande.

### ğŸ’¡ Fibonacci naÃ¯f vs mÃ©moÃ¯sation
```js
// NaÃ¯f: O(Ï†^n) ~ exponentiel
function fibNaive(n){ return (n<=1) ? n : fibNaive(n-1) + fibNaive(n-2); }

// MÃ©moÃ¯sation: O(n)
function fibMemo(){
  const memo = new Map([[0,0],[1,1]]);
  return function f(n){ if(memo.has(n)) return memo.get(n);
    const v = f(n-1) + f(n-2); memo.set(n, v); return v; };
}
const fib = fibMemo();
```

### ğŸ’¡ Tabulation (bottomâ€‘up)
```js
function fibTab(n){
  if(n<=1) return n; const dp = new Array(n+1).fill(0);
  dp[1] = 1; for(let i=2;i<=n;i++) dp[i] = dp[i-1] + dp[i-2];
  return dp[n];
}
```

### ğŸ’¡ ProblÃ¨me du rendu de monnaie (min piÃ¨ces) â€” PD
```js
function minCoins(amount, coins){
  const INF = 1e9; const dp = new Array(amount+1).fill(INF); dp[0]=0;
  for(const c of coins){
    for(let a=c; a<=amount; a++) dp[a] = Math.min(dp[a], dp[a-c] + 1);
  }
  return dp[amount] >= INF ? -1 : dp[amount];
}
```

---

## ğŸ§  7. Graphes & Arbres â€” parcours DFS/BFS

### ğŸ” ReprÃ©sentation
- **Adjacency list**: `Map<Node, Array<Node>>`.
- ComplexitÃ© **O(V+E)** pour les parcours.

### ğŸ’¡ BFS (file) â€” plus court chemin non pondÃ©rÃ©
```js
function bfs(graph, start){
  const q = [start], seen = new Set([start]);
  const order = [];
  while(q.length){
    const v = q.shift(); order.push(v);
    for(const w of (graph.get(v) || [])) if(!seen.has(w)){ seen.add(w); q.push(w); }
  }
  return order;
}
```

### ğŸ’¡ DFS (pile) â€” parcours en profondeur
```js
function dfs(graph, start){
  const st=[start], seen=new Set([start]), order=[];
  while(st.length){
    const v=st.pop(); order.push(v);
    for(const w of (graph.get(v)||[]).slice().reverse()) if(!seen.has(w)){ seen.add(w); st.push(w); }
  }
  return order;
}
```

### ğŸ’¡ Arbres â€” traversals (BST)
```js
class BSTNode { constructor(k){ this.k=k; this.l=null; this.r=null; } }
class BST {
  constructor(){ this.root=null; }
  insert(k){ this.root = this.#ins(this.root,k); }
  #ins(n,k){ if(!n) return new BSTNode(k); if(k<n.k) n.l=this.#ins(n.l,k); else n.r=this.#ins(n.r,k); return n; }
  has(k){ let n=this.root; while(n){ if(k===n.k) return true; n = k<n.k ? n.l : n.r; } return false; }
}
function inorder(n, visit){ if(!n) return; inorder(n.l,visit); visit(n.k); inorder(n.r,visit); }
function preorder(n, visit){ if(!n) return; visit(n.k); preorder(n.l,visit); preorder(n.r,visit); }
function postorder(n, visit){ if(!n) return; postorder(n.l,visit); postorder(n.r,visit); visit(n.k); }
```

---

## ğŸ§  8. Patterns dâ€™optimisation â€” Deux pointeurs & FenÃªtre glissante

### ğŸ’¡ Deux pointeurs (tableau triÃ©) â€” Somme cible
```js
function twoSumSorted(a, target){
  let i=0, j=a.length-1;
  while(i<j){
    const s=a[i]+a[j];
    if(s===target) return [i,j];
    if(s<target) i++; else j--;
  }
  return null;
}
```

### ğŸ’¡ FenÃªtre glissante â€” plus longue sousâ€‘chaÃ®ne sans rÃ©pÃ©tition
```js
function longestUniqueSubstr(s){
  const pos = new Map(); let start=0, best=0;
  for(let i=0;i<s.length;i++){
    const ch=s[i]; if(pos.has(ch) && pos.get(ch)>=start) start = pos.get(ch)+1;
    pos.set(ch,i); best = Math.max(best, i-start+1);
  }
  return best;
}
```

### ğŸ’¡ Hashing â€” Two Sum (non triÃ©) en **O(n)**
```js
function twoSum(xs, target){
  const idx = new Map();
  for(let i=0;i<xs.length;i++){
    const x=xs[i], y=target-x;
    if(idx.has(y)) return [idx.get(y), i];
    idx.set(x,i);
  }
  return null;
}
```

---

## ğŸ§ª 9. Exercices guidÃ©s

1. **Bigâ€‘O**: Donnez la complexitÃ© de chaque fragment (simple boucle, double boucle, boucle + binaire).
2. **Benchmark**: Comparez `insertionSort` vs `mergeSort` sur des tableaux de 1000, 5000, 10000.
3. **Structure**: ImplÃ©mentez une **Deque** efficace et testez `pushLeft/pushRight` en O(1) amorti.
4. **Recherche**: Ã‰crivez `binarySearchRange` pour trouver **premiÃ¨re** et **derniÃ¨re** occurrence.
5. **Tri**: ImplÃ©mentez un **quicksort** avec pivot alÃ©atoire; mesurez les temps.
6. **PD**: Modifiez `minCoins` pour retourner **les piÃ¨ces utilisÃ©es** (reconstruction).
7. **Graphes**: Ã‰crivez BFS pour retourner la **distance** depuis `start` (niveau par niveau).
8. **Arbres**: Ajoutez `remove(k)` et **rotation** Ã  votre BST (bonus AVL/Redâ€‘Black â€” aperÃ§u).

---

## âœ… 10. Checkâ€‘list Algorithmique

- [ ] Identifiez la **taille dâ€™entrÃ©e** `n` et les opÃ©rations dominantes.
- [ ] Choisissez une **structure** adaptÃ©e (Map/Set pour lookup, Heap pour prioritÃ©).
- [ ] PrÃ©fÃ©rez `O(n log n)` ou mieux aux algos `O(n^2)` pour listes grandes.
- [ ] Utilisez des **patterns** (fenÃªtre glissante, deux pointeurs, hash).
- [ ] Mesurez avec `performance.now()` **et** des tailles rÃ©alistes.
- [ ] VÃ©rifiez la **stabilitÃ©** du tri si nÃ©cessaire (multiâ€‘clÃ©s).
- [ ] Ã‰valuez les **tradeâ€‘offs** temps/espace (mÃ©moÃ¯sation, tabulation).

---

## ğŸ“¦ 11. Livrable du chapitre
Une **bibliothÃ¨que JS** `algos.js` contenant:
- `linearSearch`, `binarySearch`
- `insertionSort`, `selectionSort`, `mergeSort`, `quickSort`
- `Stack`, `Queue`, `LinkedList`, `MinHeap`
- `bfs`, `dfs`, `longestUniqueSubstr`, `twoSum`
- Un script `bench.js` avec le **harness** de benchmark.

---

## ğŸ”š RÃ©sumÃ© essentiel du Chapitre 4
- **Bigâ€‘O** fournit un **cadre** pour raisonner sur lâ€™**Ã©volutivitÃ©**; concentrezâ€‘vous sur les **termes dominants**.
- Mesurez avec `performance.now()` en **rÃ©pÃ©tant** et en **neutralisant le JIT** (warmup, anti deadâ€‘code).
- Les **structures** (Map/Set/Heap) offrent des opÃ©rations plus rapides que des tableaux selon le besoin (lookup, prioritÃ©).
- **Recherche binaire** nÃ©cessite des donnÃ©es triÃ©es; **O(log n)** vs **O(n)** pour linÃ©aire.
- Les **tris** efficaces sont **merge sort** et **quicksort** (`O(n log n)`); choisissez selon **stabilitÃ©**, **mÃ©moire**, **distribution** des donnÃ©es.
- La **rÃ©cursion** doit avoir des **cas de base**; optimisez avec **mÃ©moÃ¯sation** ou **tabulation** (PD).
- Les **parcours** de graphes/arbre (BFS/DFS) coÃ»tent **O(V+E)**; choisissez selon **objectif** (distance vs exploration).
- Les **patterns** (deux pointeurs, fenÃªtre glissante, hash) transforment des approches naÃ¯ves en solutions **linÃ©aires**.

---

> Prochain chapitre: **POO, S.O.L.I.D, MVC & Design Patterns** â€” architecture de code, principes de responsabilitÃ© et patrons classiques appliquÃ©s au Front.
